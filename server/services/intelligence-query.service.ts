/**
 * Intelligence Query Service
 * 
 * Processa consultas de intelig√™ncia contra os documentos do dossi√™
 * ou busca informa√ß√µes na web via IA.
 */

import { z } from 'zod'
import { ChatOpenAI } from '@langchain/openai'
import { ChatAnthropic } from '@langchain/anthropic'

// =============================================================================
// SCHEMA
// =============================================================================

const QueryResponseSchema = z.object({
  content: z.string().describe('Resposta completa e detalhada √† pergunta do usu√°rio, baseada no material fornecido'),
  noteType: z.enum(['insight', 'curiosity', 'research']).describe('Tipo de informa√ß√£o da resposta: insight = an√°lise/conex√£o, curiosity = fato surpreendente, research = dado factual')
})

// =============================================================================
// INTERFACES
// =============================================================================

export interface IntelligenceQueryRequest {
  query: string
  source: 'docs' | 'web'
  theme: string
  sources?: Array<{ title: string; content: string; sourceType: string }>
  existingNotes?: Array<{ content: string; noteType: string }>
}

export interface IntelligenceQueryResult {
  content: string
  noteType: 'insight' | 'curiosity' | 'research'
  usage?: { inputTokens: number; outputTokens: number; totalTokens: number }
  provider: string
  model: string
}

// =============================================================================
// SERVICE
// =============================================================================

export async function intelligenceQuery(
  request: IntelligenceQueryRequest,
  providerConfig: { name: string; apiKey: string; model?: string; baseUrl?: string }
): Promise<IntelligenceQueryResult> {
  console.log(`[IntelligenceQuery] üîé Consulta: "${request.query}" (source: ${request.source})`)

  const providerName = providerConfig.name.toLowerCase()
  let structuredLlm: any

  if (providerName === 'anthropic') {
    const queryModel = process.env.ANTHROPIC_MODEL_INSIGHTS || providerConfig.model || 'claude-sonnet-4-20250514'
    const model = new ChatAnthropic({
      anthropicApiKey: providerConfig.apiKey,
      modelName: queryModel,
      temperature: 0.6,
      maxTokens: 2048
    })
    structuredLlm = model.withStructuredOutput(QueryResponseSchema, { includeRaw: true })
  } else {
    const model = new ChatOpenAI({
      openAIApiKey: providerConfig.apiKey,
      modelName: providerConfig.model ?? 'gpt-4o-mini',
      configuration: {
        baseURL: providerConfig.baseUrl ?? 'https://api.openai.com/v1'
      },
      temperature: 0.6,
      timeout: 60000,
      maxRetries: 2
    })
    structuredLlm = model.withStructuredOutput(QueryResponseSchema, { includeRaw: true })
  }

  const systemPrompt = buildQuerySystemPrompt(request.source)
  const userPrompt = buildQueryUserPrompt(request)

  const startTime = Date.now()

  const response = await structuredLlm.invoke([
    { role: 'system', content: systemPrompt },
    { role: 'user', content: userPrompt }
  ])

  const elapsed = ((Date.now() - startTime) / 1000).toFixed(1)
  const content = response.parsed as z.infer<typeof QueryResponseSchema>

  const usage = response.raw?.usage_metadata ?? response.raw?.usage ?? {}
  const inputTokens = usage?.input_tokens ?? 0
  const outputTokens = usage?.output_tokens ?? 0
  const totalTokens = usage?.total_tokens ?? (inputTokens + outputTokens)

  console.log(`[IntelligenceQuery] ‚úÖ Resposta em ${elapsed}s ‚Äî ${totalTokens} tokens`)

  return {
    content: content.content,
    noteType: content.noteType,
    usage: { inputTokens, outputTokens, totalTokens },
    provider: providerName.toUpperCase(),
    model: providerConfig.model ?? (providerName === 'anthropic' ? 'claude-sonnet-4-20250514' : 'gpt-4o-mini')
  }
}

// =============================================================================
// PROMPTS
// =============================================================================

function buildQuerySystemPrompt(source: 'docs' | 'web'): string {
  if (source === 'docs') {
    return `Voc√™ √© um analista de intelig√™ncia editorial. O usu√°rio far√° uma pergunta sobre o material de um dossi√™ (fontes documentais + notas existentes).

Sua fun√ß√£o √© responder a pergunta com base EXCLUSIVAMENTE no material fornecido adiante. Seja detalhado, preciso e cite trechos ou dados espec√≠ficos sempre que poss√≠vel.

## REGRAS:
- Responda SOMENTE com base no material do dossi√™ fornecido
- Se a informa√ß√£o n√£o estiver no material, diga claramente: "Esta informa√ß√£o n√£o consta no material do dossi√™"
- Cite fontes espec√≠ficas quando aplic√°vel (ex: "Conforme mencionado na fonte X...", "A fonte Y indica...")
- Seja conciso mas completo
- Escreva em portugu√™s brasileiro
- Classifique sua resposta como insight (an√°lise/conex√£o), curiosity (fato surpreendente) ou research (dado factual)`
  }

  return `Voc√™ √© um pesquisador editorial especializado. O usu√°rio far√° uma pergunta sobre um tema e voc√™ deve responder com seu conhecimento geral, trazendo informa√ß√µes verific√°veis, dados relevantes e contexto.

O tema do dossi√™ √© fornecido para contexto, mas sua resposta deve ir al√©m do material ‚Äî trazendo conhecimento externo.

## REGRAS:
- Traga dados complementares ao material do dossi√™
- Priorize informa√ß√µes verific√°veis: datas, nomes, locais, fontes hist√≥ricas
- Inclua detalhes que enrique√ßam a narrativa (perfeitos para curiosidades e fatos pouco conhecidos)
- Se n√£o tiver certeza de um dado, indique com "segundo registros..." ou "h√° relatos de que..."
- Seja conciso mas detalhado
- Escreva em portugu√™s brasileiro
- Classifique sua resposta como insight (an√°lise/conex√£o), curiosity (fato surpreendente) ou research (dado factual)`
}

function buildQueryUserPrompt(request: IntelligenceQueryRequest): string {
  let prompt = `TEMA DO DOSSI√ä: ${request.theme}\n\n`

  if (request.source === 'docs') {
    // Incluir todas as fontes do dossi√™ (arquitetura flat/democratizada)
    if (request.sources && request.sources.length > 0) {
      const totalBudget = 16000
      const perSourceChars = Math.floor(totalBudget / request.sources.length)
      prompt += `üìö FONTES DO DOSSI√ä:\n`
      request.sources.forEach((source, i) => {
        const truncated = source.content.length > perSourceChars
          ? source.content.substring(0, perSourceChars) + '...'
          : source.content
        prompt += `[${i + 1}] (${source.sourceType}) ${source.title}\n${truncated}\n---\n`
      })
      prompt += '\n'
    }

    if (request.existingNotes && request.existingNotes.length > 0) {
      const notesText = request.existingNotes.slice(0, 20).map((n, i) => `[${i + 1}] (${n.noteType}) ${n.content}`).join('\n')
      prompt += `üß† NOTAS EXISTENTES:\n${notesText}\n\n`
    }
  }

  prompt += `\n‚ùì PERGUNTA DO USU√ÅRIO:\n${request.query}\n\nResponda de forma detalhada e estruturada.`

  return prompt
}
