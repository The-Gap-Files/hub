/**
 * Anthropic Cache Helper
 *
 * Constr√≥i mensagens LangChain com cache_control para prompt caching da Anthropic.
 *
 * Estrat√©gia de mensagens:
 *   SystemMessage: System prompt da tarefa (varia por etapa ‚Äî N√ÉO cacheado)
 *   HumanMessage:  [content multi-part]
 *     ‚Üí Part 0: Dossi√™ can√¥nico (cache_control: ephemeral) ‚Üê CACHEADO
 *     ‚Üí Part 1: Instru√ß√µes espec√≠ficas da tarefa             ‚Üê N√ÉO cacheado
 *     ‚Üí Part N: Imagens multimodal (se houver)              ‚Üê N√ÉO cacheado
 *
 * O dossi√™ vai como primeiro content block do HumanMessage com cache_control,
 * permitindo que o system prompt mude livremente entre chamadas (monetization,
 * story-architect, script) sem invalidar o cache do dossi√™.
 *
 * @see docs/roadmap/08-prompt-caching-pipeline.md
 */

import { SystemMessage, HumanMessage } from '@langchain/core/messages'
import type { BaseMessage, MessageContentComplex } from '@langchain/core/messages'
import { estimateDossierTokens, MIN_CACHE_TOKENS } from '../../utils/dossier-prompt-block'

// =============================================================================
// TIPOS
// =============================================================================

export interface CacheablePromptConfig {
  /** Bloco can√¥nico do dossi√™ (ser√° cacheado) */
  dossierBlock: string
  /** System prompt da tarefa (skill + par√¢metros t√©cnicos) */
  systemPrompt: string
  /** Instru√ß√µes espec√≠ficas (monetizationContext, storyOutline, formato, etc.) */
  taskPrompt: string
  /** Imagens multimodal (n√£o-cache√°veis) */
  images?: Array<{ data: any; mimeType: string; title?: string }>
  /** Provider atual (s√≥ aplica cache se for Anthropic) */
  providerName?: string
}

export interface CacheableResult {
  messages: BaseMessage[]
  cacheEnabled: boolean
  estimatedCacheTokens: number
}

// =============================================================================
// FEATURE FLAG
// =============================================================================

/**
 * Verifica se o prompt caching est√° habilitado.
 * Controlado pela env ENABLE_PROMPT_CACHING (default: true).
 */
export function isPromptCachingEnabled(): boolean {
  const flag = process.env.ENABLE_PROMPT_CACHING
  if (flag === undefined || flag === '') return true // Default: habilitado
  return flag.toLowerCase() === 'true' || flag === '1'
}

/**
 * Verifica se deve aplicar cache para um provider espec√≠fico.
 * S√≥ Anthropic suporta cache_control.
 */
export function shouldApplyCache(providerName?: string): boolean {
  if (!isPromptCachingEnabled()) return false
  if (!providerName) return false
  return providerName.toLowerCase().includes('anthropic') || providerName.toLowerCase().includes('claude')
}

// =============================================================================
// MESSAGE BUILDER
// =============================================================================

/**
 * Constr√≥i mensagens com cache_control para Anthropic.
 *
 * Se caching N√ÉO est√° habilitado ou provider N√ÉO √© Anthropic,
 * retorna mensagens normais (sem cache_control).
 */
export function buildCacheableMessages(config: CacheablePromptConfig): CacheableResult {
  const estimatedTokens = estimateDossierTokens(config.dossierBlock)
  const applyCache = shouldApplyCache(config.providerName) && estimatedTokens >= MIN_CACHE_TOKENS

  // System message (sempre igual, sem cache_control)
  const systemMessage = new SystemMessage(config.systemPrompt)

  if (applyCache) {
    // ‚îÄ‚îÄ COM CACHE ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    // HumanMessage com content multi-part (array de blocos)
    const contentParts: MessageContentComplex[] = [
      // Part 0: Dossi√™ can√¥nico ‚Üí CACHEADO
      {
        type: 'text' as const,
        text: `üì¶ DOSSI√ä DO CONTE√öDO (BASE DE CONHECIMENTO):\n\n${config.dossierBlock}`,
        // cache_control via additionalKwargs do LangChain ‚Üí passado direto √† API Anthropic
        cache_control: { type: 'ephemeral' }
      } as any,
      // Part 1: Instru√ß√µes da tarefa ‚Üí N√ÉO cacheado
      {
        type: 'text' as const,
        text: config.taskPrompt
      }
    ]

    // Parts adicionais: imagens multimodal
    if (config.images && config.images.length > 0) {
      for (const img of config.images) {
        if (!img.data) continue
        const base64 = Buffer.isBuffer(img.data)
          ? img.data.toString('base64')
          : Buffer.from(img.data).toString('base64')

        // Normalizar media_type para Anthropic (image/jpg ‚Üí image/jpeg)
        let mediaType = img.mimeType || 'image/jpeg'
        if (mediaType === 'image/jpg') mediaType = 'image/jpeg'

        // Validar media_type aceito pelo Anthropic
        const validTypes = ['image/jpeg', 'image/png', 'image/gif', 'image/webp']
        if (!validTypes.includes(mediaType)) {
          console.warn(`[PromptCache] ‚ö†Ô∏è Pulando imagem com media_type n√£o suportado: ${mediaType} (Anthropic aceita: jpeg, png, gif, webp)`)
          continue // Pular esta imagem
        }

        // Formato nativo do Anthropic (n√£o image_url)
        contentParts.push({
          type: 'image' as const,
          source: {
            type: 'base64' as const,
            media_type: mediaType,
            data: base64
          }
        } as any)
      }
    }

    const humanMessage = new HumanMessage({ content: contentParts as any })

    console.log(`[PromptCache] ‚úÖ Cache HABILITADO ‚Äî dossi√™: ~${estimatedTokens} tokens (m√≠n: ${MIN_CACHE_TOKENS})`)

    return {
      messages: [systemMessage, humanMessage],
      cacheEnabled: true,
      estimatedCacheTokens: estimatedTokens
    }
  } else {
    // ‚îÄ‚îÄ SEM CACHE (provider n√£o-Anthropic ou dossi√™ muito pequeno) ‚îÄ‚îÄ
    const reason = !shouldApplyCache(config.providerName)
      ? `provider=${config.providerName || 'unknown'}`
      : `tokens=${estimatedTokens} < m√≠n=${MIN_CACHE_TOKENS}`

    console.log(`[PromptCache] ‚è≠Ô∏è Cache DESABILITADO (${reason})`)

    // Mensagem simples: dossi√™ + instru√ß√µes concatenados
    const fullPrompt = `${config.dossierBlock}\n\n${config.taskPrompt}`
    const humanMessage = new HumanMessage(fullPrompt)

    return {
      messages: [systemMessage, humanMessage],
      cacheEnabled: false,
      estimatedCacheTokens: 0
    }
  }
}

// =============================================================================
// LOGGING HELPER
// =============================================================================

/**
 * Extrai e loga m√©tricas de cache da resposta do LLM Anthropic.
 * Chamado ap√≥s cada invoke() para observabilidade.
 */
export function logCacheMetrics(
  stage: string,
  rawMessage: any
): { cacheCreationTokens: number; cacheReadTokens: number; inputTokens: number } {
  const usage = rawMessage?.usage_metadata
    || rawMessage?.response_metadata?.usage
    || rawMessage?.usage
    || {}

  const cacheCreationTokens = usage.cache_creation_input_tokens ?? 0
  const cacheReadTokens = usage.cache_read_input_tokens ?? 0
  const inputTokens = usage.input_tokens ?? 0

  if (cacheCreationTokens > 0 || cacheReadTokens > 0) {
    const hitRate = cacheReadTokens > 0
      ? ((cacheReadTokens / (cacheReadTokens + inputTokens)) * 100).toFixed(1)
      : '0.0'

    console.log(
      `[PromptCache] üìä ${stage} ‚Äî ` +
      `cache_write: ${cacheCreationTokens}, ` +
      `cache_read: ${cacheReadTokens}, ` +
      `input: ${inputTokens}, ` +
      `hit_rate: ${hitRate}%`
    )
  }

  return { cacheCreationTokens, cacheReadTokens, inputTokens }
}
