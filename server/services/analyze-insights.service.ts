/**
 * Analyze Insights Service
 * 
 * Usa LangChain + Structured Output para analisar o conte√∫do do dossi√™
 * e gerar automaticamente insights neurais, curiosidades e dados de pesquisa.
 */

import { z } from 'zod'
import { SystemMessage, HumanMessage } from '@langchain/core/messages'
import { createLlmForTask, getAssignment } from './llm/llm-factory'

// =============================================================================
// SCHEMA - Formato estruturado que a IA deve retornar
// =============================================================================

const InsightItemSchema = z.object({
  content: z.string().describe('O texto do insight, curiosidade ou dado de pesquisa, escrito de forma clara e concisa'),
  noteType: z.enum(['insight', 'curiosity', 'research']).describe('insight = conex√£o anal√≠tica, padr√£o narrativo ou √¢ngulo editorial. curiosity = fato surpreendente, contradi√ß√£o ou ponto pouco explorado. research = dado de pesquisa estruturado: fato verific√°vel, estat√≠stica, data, nome ou refer√™ncia documental')
})

const PersonItemSchema = z.object({
  name: z.string().describe('Nome completo da pessoa'),
  role: z.string().optional().describe('Papel narrativo: investigador, v√≠tima, suspeito, testemunha, cientista, l√≠der, autor, etc.'),
  description: z.string().describe('Descri√ß√£o breve da pessoa e sua relev√¢ncia no contexto do dossi√™ (1-2 frases)'),
  visualDescription: z.string().optional().describe('Descri√ß√£o visual da pessoa para consist√™ncia em gera√ß√£o de imagens/v√≠deos: apar√™ncia f√≠sica, vestimenta t√≠pica, express√£o, edad aparente. Ex: "Homem caucasiano, 50 anos, cabelo grisalho curto, terno escuro, express√£o severa"'),
  aliases: z.array(z.string()).optional().describe('Apelidos, codinomes ou outros nomes pelos quais a pessoa √© conhecida'),
  relevance: z.enum(['primary', 'secondary', 'mentioned']).describe('primary = protagonista ou figura central. secondary = papel importante mas n√£o central. mentioned = citado brevemente')
})

const AnalysisResponseSchema = z.object({
  items: z.array(InsightItemSchema).min(1).max(15).describe('Lista de insights, curiosidades e dados de pesquisa extra√≠dos do material'),
  persons: z.array(PersonItemSchema).max(10).describe('Lista de pessoas-chave identificadas no material. Apenas pessoas reais ou personagens relevantes, n√£o figuras gen√©ricas.')
})

type AnalysisResponse = z.infer<typeof AnalysisResponseSchema>

// =============================================================================
// TIPOS
// =============================================================================

export interface AnalyzeInsightsRequest {
  theme: string
  sources?: Array<{ title: string; content: string; sourceType: string; weight?: number }>
  existingNotes?: Array<{ content: string; noteType: string }>
  images?: Array<{ description: string }>
  existingPersons?: Array<{ name: string }>
}

export interface AnalyzeInsightsResult {
  items: Array<{ content: string; noteType: 'insight' | 'curiosity' | 'research' }>
  persons: Array<{ name: string; role?: string; description: string; visualDescription?: string; aliases?: string[]; relevance: 'primary' | 'secondary' | 'mentioned' }>
  usage?: { inputTokens: number; outputTokens: number; totalTokens: number }
  provider: string
  model: string
}

// =============================================================================
// SERVICE
// =============================================================================

export async function analyzeInsights(
  request: AnalyzeInsightsRequest
): Promise<AnalyzeInsightsResult> {
  console.log('[AnalyzeInsights] üß† Iniciando an√°lise neural do dossi√™...')

  // Criar modelo via LLM Factory (provider/modelo configur√°vel via UI)
  const assignment = await getAssignment('analysis')
  const model = await createLlmForTask('analysis')
  const m = model as any
  const isGroqLlama4 = assignment.provider.toLowerCase().includes('groq') && assignment.model.includes('llama-4')
  const structuredLlm = assignment.provider === 'replicate' && typeof m.withStructuredOutputReplicate === 'function'
    ? m.withStructuredOutputReplicate(AnalysisResponseSchema, { includeRaw: true })
    : m.withStructuredOutput(AnalysisResponseSchema, { includeRaw: true, ...(isGroqLlama4 ? { method: 'jsonMode' } : {}) })

  // Montar o prompt
  const systemPrompt = buildSystemPrompt()
  const userPrompt = buildUserPrompt(request)

  console.log(`[AnalyzeInsights] üì§ Enviando para ${assignment.provider} (${assignment.model})...`)

  const messages = [
    new SystemMessage(systemPrompt),
    new HumanMessage(userPrompt)
  ]

  try {
    const startTime = Date.now()
    const { invokeWithLogging } = await import('../utils/llm-invoke-wrapper')
    const result = await invokeWithLogging(structuredLlm, messages, {
      taskId: 'analyze-insights',
      provider: assignment.provider,
      model: assignment.model
    })
    const content = result.parsed as AnalysisResponse
    const rawMessage = result.raw as any
    const elapsed = ((Date.now() - startTime) / 1000).toFixed(2)

    // Extrair token usage
    const usage = rawMessage?.usage_metadata || rawMessage?.response_metadata?.usage
    const inputTokens = usage?.input_tokens ?? 0
    const outputTokens = usage?.output_tokens ?? 0
    const totalTokens = usage?.total_tokens ?? (inputTokens + outputTokens)

    const personsCount = content.persons?.length || 0
    console.log(`[AnalyzeInsights] ‚úÖ An√°lise conclu√≠da em ${elapsed}s ‚Äî ${content.items.length} itens + ${personsCount} pessoas`)
    console.log(`[AnalyzeInsights] üìä Tokens: ${inputTokens} input + ${outputTokens} output = ${totalTokens} total`)

    const insights = content.items.filter(i => i.noteType === 'insight').length
    const curiosities = content.items.filter(i => i.noteType === 'curiosity').length
    const research = content.items.filter(i => i.noteType === 'research').length
    console.log(`[AnalyzeInsights] üí° ${insights} insights + üîç ${curiosities} curiosidades + üìä ${research} dados de pesquisa + üë§ ${personsCount} pessoas`)

    return {
      items: content.items,
      persons: content.persons || [],
      usage: { inputTokens, outputTokens, totalTokens },
      provider: assignment.provider.toUpperCase(),
      model: assignment.model
    }
  } catch (error: any) {
    const { handleGroqJsonValidateError } = await import('../utils/groq-error-handler')
    const result = handleGroqJsonValidateError<any>(error, '[AnalyzeInsights]')

    if (result.success) {
      console.warn('[AnalyzeInsights] ‚ö†Ô∏è Usando resposta parcial do failed_generation')
      return {
        items: result.data.items || [],
        persons: result.data.persons || [],
        usage: { inputTokens: 0, outputTokens: 0, totalTokens: 0 },
        provider: assignment.provider.toUpperCase(),
        model: assignment.model
      }
    }

    console.error('[AnalyzeInsights] ‚ùå Erro na an√°lise:', error)
    throw error
  }
}

// =============================================================================
// PROMPT BUILDERS
// =============================================================================

function buildSystemPrompt(): string {
  return `Voc√™ √© um analista de intelig√™ncia editorial especializado em extrair insights profundos, curiosidades surpreendentes, dados de pesquisa estruturados e PESSOAS-CHAVE de material bruto.

Sua fun√ß√£o √© analisar o dossi√™ fornecido (fontes do dossi√™ + notas existentes) e retornar:
1. Uma lista de descobertas divididas em tr√™s categorias (items)
2. Uma lista de pessoas-chave identificadas no material (persons)

## INSIGHT NEURAL (noteType: "insight")
- Conex√µes n√£o-√≥bvias entre informa√ß√µes do material
- Padr√µes narrativos que podem ser explorados
- √Çngulos editoriais √∫nicos e diferenciados
- Contradi√ß√µes internas que geram tens√£o narrativa
- Rela√ß√µes causais impl√≠citas no material

## CURIOSIDADE (noteType: "curiosity")  
- Fatos surpreendentes ou pouco conhecidos
- Dados estat√≠sticos impactantes
- Detalhes sensoriais ou humanos que enriquecem a narrativa
- Elementos que geram engajamento e reten√ß√£o do p√∫blico
- Pontos que provocam reflex√£o ou debate

## DADO DE PESQUISA (noteType: "research")
- Fatos verific√°veis e objetivos (nomes, datas, locais)
- Estat√≠sticas e n√∫meros concretos mencionados no material
- Refer√™ncias documentais ou bibliogr√°ficas
- Linhas do tempo e sequ√™ncias cronol√≥gicas
- Dados que servem como base factual para roteiros e scripts

## PESSOAS-CHAVE (persons)
Identifique todas as pessoas relevantes mencionadas no material:
- **name**: Nome completo como aparece no material
- **role**: Papel narrativo (investigador, v√≠tima, suspeito, testemunha, cientista, l√≠der, pol√≠tico, jornalista, etc.)
- **description**: Quem √© esta pessoa e por que √© relevante no contexto (1-2 frases)
- **visualDescription**: Descri√ß√£o visual da pessoa para gera√ß√£o de imagens/v√≠deos consistentes. Inclua: apar√™ncia f√≠sica, idade aparente, vestimenta t√≠pica, express√£o. Ex: "Homem caucasiano, ~50 anos, cabelo grisalho curto, terno escuro, express√£o severa"
- **aliases**: Lista de apelidos, codinomes ou outros nomes conhecidos
- **relevance**: "primary" (protagonista/figura central), "secondary" (papel importante mas n√£o central), "mentioned" (citado brevemente)

## REGRAS:
- Gere entre 6 e 15 itens no total
- Balance entre as tr√™s categorias (priorize o que o material oferece)
- Gere pelo menos 2 itens de cada categoria quando poss√≠vel
- Cada item deve ser autocontido e compreens√≠vel isoladamente
- Escreva em portugu√™s brasileiro
- Seja espec√≠fico ‚Äî evite generalidades vagas
- N√ÉO repita informa√ß√µes que j√° existam nas notas existentes do dossi√™
- N√ÉO repita pessoas que j√° foram extra√≠das anteriormente
- Priorize descobertas que agreguem valor √† produ√ß√£o de conte√∫do
- Para visualDescription, seja espec√≠fico o suficiente para que um modelo de IA consiga gerar a pessoa consistentemente entre cenas`
}

// =============================================================================
// TRUNCAMENTO INTELIGENTE
// =============================================================================

/** Limite seguro de tokens para o prompt (deixa margem para system prompt + output) */
const MAX_PROMPT_TOKENS = 150_000
const CHARS_PER_TOKEN = 4

function estimateTokens(text: string): number {
  return Math.ceil(text.length / CHARS_PER_TOKEN)
}

function truncateText(text: string, maxTokens: number): string {
  const maxChars = maxTokens * CHARS_PER_TOKEN
  if (text.length <= maxChars) return text
  return text.slice(0, maxChars) + '\n\n[... CONTE√öDO TRUNCADO POR LIMITE DE CONTEXTO ...]'
}

function buildUserPrompt(request: AnalyzeInsightsRequest): string {
  // Budget unificado: fontes (85%), notas+imagens (15%)
  const sourcesBudget = Math.floor(MAX_PROMPT_TOKENS * 0.85)
  const metaBudget = Math.floor(MAX_PROMPT_TOKENS * 0.15)

  let prompt = `Analise o seguinte dossi√™ e extraia insights neurais, curiosidades e dados de pesquisa:\n\n`

  prompt += `üìã TEMA: ${request.theme}\n\n`

  // Fontes (todas tratadas igualmente ‚Äî arquitetura flat/democratizada)
  if (request.sources && request.sources.length > 0) {
    // Calcular budget proporcional ao peso de cada fonte
    const totalWeight = request.sources.reduce((sum, s) => sum + (s.weight ?? 1.0), 0)
    prompt += `üìö FONTES DO DOSSI√ä:\n`
    request.sources.forEach((source, i) => {
      const weight = source.weight ?? 1.0
      const perSourceBudget = Math.floor(sourcesBudget * (weight / totalWeight))
      const truncatedContent = truncateText(source.content, perSourceBudget)
      const weightLabel = weight !== 1.0 ? ` [peso: ${weight}]` : ''
      prompt += `[${i + 1}] (${source.sourceType}) ${source.title}${weightLabel}\n${truncatedContent}\n---\n`
    })
    prompt += '\n'
  }

  // Imagens e notas existentes (usa budget de meta)
  let metaUsed = 0

  if (request.images && request.images.length > 0) {
    prompt += `üñºÔ∏è IMAGENS DE REFER√äNCIA (descri√ß√µes):\n`
    request.images.forEach((img, i) => {
      prompt += `[${i + 1}] ${img.description}\n`
    })
    prompt += '\n'
    metaUsed += estimateTokens(request.images.map(i => i.description).join('\n'))
  }

  if (request.existingNotes && request.existingNotes.length > 0) {
    const notesRemaining = metaBudget - metaUsed
    const notesText = request.existingNotes.map((note, i) => `[${i + 1}] (${note.noteType}) ${note.content}`).join('\n')
    const truncatedNotes = truncateText(notesText, notesRemaining)
    prompt += `üß† NOTAS J√Å EXISTENTES (N√ÉO repetir estes):\n${truncatedNotes}\n\n`
  }

  if (request.existingPersons && request.existingPersons.length > 0) {
    const personsText = request.existingPersons.map((p, i) => `[${i + 1}] ${p.name}`).join('\n')
    prompt += `üë§ PESSOAS J√Å EXTRA√çDAS (N√ÉO repetir):\n${personsText}\n\n`
  }

  prompt += `\nRetorne os insights, curiosidades, dados de pesquisa E pessoas-chave no formato JSON estruturado.`

  // Log de diagn√≥stico
  const totalTokens = estimateTokens(prompt)
  console.log(`[AnalyzeInsights] üìè Prompt: ~${totalTokens.toLocaleString()} tokens estimados`)

  return prompt
}
